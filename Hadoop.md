# # Hadoop

## 1. Hadoop 개념

### 1-1. Hadoop

- 대량의 데이터를 처리하기 위한 **병렬 분산 처리 소프트웨어**
- 분산 파일 시스템과의 강한 연계를 통해, 높은 스루풋 처리를 실현하는 분산 처리 소프트웨어
  - 분산 파일 시스템
  - 병렬 분산 처리를 실현하는 프레임워크
- 자바 기반으로 개발되어 일반적인 서버에서 동작
- Scale-Out
- 관계현 데이터베이스나 검색 엔진과는 다름
- 오픈 소스 프로젝트

[이미지1]



### 1-2. 시스템 구성과 아키텍처

#### 1-2-1. 서버 구성

- Hadoop을 구성하는 서버는 클러스터 전체를 관리하는 '마스터 서버군' 과 실제로 데이터를 저장하고 처리하는 '슬레이브 서버군' 

| 프로젝트명 | 설명                                                         |
| ---------- | ------------------------------------------------------------ |
| HDFS       | 높은 스루풋을 유지하면서 동시에 신뢰성을 추구하는 분산 파일 시스템 |
| MapReduce  | 클러스터 환경에서 병렬 분산 처리를 수행하기 위한 프레임워크  |
| Hive       | Hadoop 조작을 쉽게 하기 위한 SQL 형식의 인터페이스           |
| Pig        | Hadoop 데이터 흐름을 기술하기 위한 스크립트 언어 방식 인터페이스 |
| Sqoop      | DBMS와 Hadoop 사이의 데이터 이동을 구현하는 커넥터           |
| HBase      | 대용량 테이블을 관리하기 위해서 확장성을 추구한 Key-Value 방식 저장소 |
| ZooKeeper  | 분산 클러스터 환경에서 동작하는 어플리케이션을 관리하기 위한 제품 |

[이미지2]

- HDFS의 마스터 서버를 **'Name Node'** . 클러스터 전체에 걸쳐서 데이터가 어디에 배치되어 있는지 등의 메타데이터를 관리

  슬레이브 서버를 **'DataNode'** . 실제 데이터를 읽고 쓰는 역할

- MapReduce의 마스터 서버를 **'JobTracker'** . 하나의 Job을 Task라 불리는 복수의 처리로 분할하여 각 슬레이브 서버에 할당

  슬레이브 서버를 **'TaskTracker'** . 할당된 Task를 실행하고 결과를 반환

- 각각의 마스터 서버인 **'Name Node'**,  **'JobTracker'** 는 각 한 대 씩

- 슬레이브 서버는 여러 대로 구성되며, **'DataNode'** , **'TaskTracker'** 가 같은 서버에 설치되는 것이 일반적

#### 1-2-2. HDFS : Hadoop 분산 파일 시스템

- HDFS는 대용량 파일에 높은 처리량으로 접근할 수 있도록 설계된 분산 파일 시스템
- 분산 파일 시스템은 복수의 서버에서 규모가 큰 하나의 파일 시스템을 제공
- 각 슬레이브 서버(DataNode)에 있는 ext4 같은 로컬 파일 시스템 상에 만들어지는 **오버레이 파일 시스템**
- HDFS 상에 배치된 파일은 64MB 단위의 블록으로 분할되어 각 장비에 저장되지만, 각 블록 데이터는 ext4 같은 로컬 파일 시스템의 파일로 취급
- 하나의 파일을 복수의 '블록'으로 분할하고 각각의 블록을 복수의 서버에 다중으로 기록하는 replication 기능
- 마스터 서버인 **'Name Node'**가 고장나면 HDFS 전체가 장애

[이미지3]

#### 1-2-3. Hadoop MapReduce 프레임워크

- 대규모 데이터 집합을 처리하기 위한 프로그래밍 모델
- 처리를 병렬로 실행하기 위해 하나의 Job을 독립된 Task로 나누어서 실행

##### 처리 흐름

- **Map 처리**와 **Reduce 처리** 두 단계로 구성
- 어플리케이션 개발자는 Map 처리와 Reduce 처리로 각각 어떤 동작을 할 것인지 정의
- **Map 처리**는 주로 입력파일을 한 줄씩 읽어서 필터링 등의 처리
- **Reduce 처리**는 데이터 집약
- **Map 처리**와 **Reduce 처리** 사이에는 **'Shuffle'** 처리가 자동 실행
- 어떤 처리든 데이터는 Key-value 쌍
- **Map 처리**
  1. 입력 데이터 집합을 분할해서 각각을 Map 태스크에 할당
  2. 각 Map 태스크를 TaskTracker에 할당
  3. 각 Map 태스크는 입력 데이터로부터 한 건씩 Key-value 쌍을 꺼내 사용자가 정의한 Map 처리를 수행하고 처리 결과 출력
- **Shuffle 처리**
  4. Map 처리 후 데이터를 정렬해 같은 키를 가진 데이터를 모음(슬레이브 서버 간에 네트워크 트래픽 발생)

- **Reduce 처리**
  5. 키별로 모아진 데이터에 대해 Reduce 처리



## 2. HDFS

### 2-1. Hadoop 파일 시스템

#### 2-1-1. 분산 파일 시스템

- 여러 대의 노드 상에 하나의 파일 시스템 공간 생성
- HDFS는 범용 파일 시스템 위에서 동작
- 지정된 디렉터리 이하를 데이터 영역으로 사용하며 각 노드 상의 디스크 공간을 합쳐 하나의 파일 시스템 생성

#### 2-1-2. 특징

- 대용량 데이터를 범용 서버만으로 처리 가능
- 용량 확장성
- 순차적 접근으로 높은 처리량
  - 처리 속도(latency) 보다 처리량(throughput) 중시
  - Write Once, Read Many 방식
- 슬레이브 노드의 일부가 고장나도 데이터 손실 방지



### 2-2. 구조

#### 2-2-1. 아키텍처

[이미지4]

- Master-Slave 구성
- **DateNode**
  - 슬레이브 서버
  - 파일의 데이터 블록을 저장
- **NameNode**
  - 마스터 서버
  - HDFS 관리
  - 메타데이터를 관리하는 것이 **SecondaryNameNode**
  - 사용자는 HDFS Client를 경유하여 HDFS에 데이터 기록

#### 2-2-2. DataNode

- HDFS를 통해 투입된 데이터 유지

##### 각 DataNode 상의 데이터 배치와 HDFS

- HDFS는 자바로 구현된 미들웨어로 OS 보다 상위 계층에서 제공되는 파일 시스템
- HDFS 상에 저장한 파일의 실체는 각 DataNode 상의 로컬 파일로 존재

##### HDFS 상의 파일과 블록

- 파일은 복수의 블록으로 분할되어 HDFS에 저장
- 블록의 실체가 로컬 파일 시스템에 저장된 파일이고 크기도 가변적이기 때문에, 블록 크기가 아닌 실제 사용하는 크기만큼 영역 확보

##### 블록 리플리케이션

- HDFS 상의 파일 I/O는 블록 단위
- 초기 블록 크기는 64MB
- 여러 대의 DataNode 상에 복제본(리플리케이션)

#### 2-2-3. NameNode

##### 메타데이터 관리

- 메타데이터 : 파일 속정 정보, 파일 시스템 정보, '어떤 블록이 어떤 파일의 어떤 부분에 있는가' 라는 정보 기록
- 메타데이터를 기반으로 HDFS 전체 관리
- 메모리에서 관리

##### HDFS 사용 상황 확인

- HDFS  전체 사용 상황 관리
- DataNode의 HDFS용 영역 상태 관리
- 블록의 본제본 수 관리

#####  클라이언트의 HDFS 처리 요청 접수

- 파일 요청 시, 가장 처음 접속하는 것이 NameNode
- 클라이언트 요청 시, 메타데이터를 바탕으로 대상 블록이 있는 DataNode 리스트 전달

##### DataNode 다운 여부 감시

- DataNode의 다운 여부 감시
- DataNode는 일정 간격으로 Heartbeat 를 NameNode에 전송



### 2-3. HDFS 파일 I/O 흐름

- 사용자는 HDFS 클라이언트를 통해 데이터 저장
- HDFS 클라이언트는 NameNode 와 처음으로 통신하고 어떤 DataNode와 작업할 지 파악
- 실제 데이터 교환은 NameNode가 아닌 DataNode와 직접 교환

#### 2-3-1. HDFS에 파일 저장



### 2-4. 메타데이터

#### 2-4-1. 메타데이터 정보

- 메타데이터는 파일 속성 정보나 디렉터리 구조 등의 파일 시스템 이미지와 DataNode와 블록의 대응 정보가 포함

| 항목                                        | 예                            |
| ------------------------------------------- | ----------------------------- |
| 파일명(디렉터리명)                          | foo.txt                       |
| 부모 디렉터리                               | /path/to                      |
| 크기                                        | 100GB                         |
| 소유자:소속그룹                             | hdfs:hadoop                   |
| 속성                                        | -rw-r-r-                      |
| 블록ID와 해당 블록을 보유하고 있는 DataNode | {blk_001,{NodeA,NodeB,NodeE}} |

#### 2-4-2. fsimage와 edits

- 메모리 상에서 관리되고 있는 메타데이터 내의 파일 시스템 이미지는 '체크포인트' 타이밍에 NameNode 의 로컬 파일 시스템에 생성 = fsimage
- HDFS에서는 파일 변경을 트랜잭션으로 관리
- 파일 처리 시 마다 NameNode의 메모리와 로컬 파일 시스템에 편집 로그 생성 = edits
- 편집 로그는 HDFS에 기록한 편집 이력 등으로, 메모리 상에서 관리되고 있는 파일 시스템 이미지에 적용함으로써 fsimage를 최신 상태로 유지

#### 2-4-3. 메모리, 디스크 동기, 체크포인트

- fsimage는 '체크포인트' 타이밍에만 메모리 내의 파일 시스템 이미지와 동기화
- edits는 HDFS에 기록할 때마다 메모리와 로컬 파일 시스템 내용이 동기화
- 항상 최신 변경 상태를 기록하고 있는 edits를 사용함으로써 fsimage를 최신화하고 HDFS의 파일 시스템 이미지를 구축하는 것이 가능

#### 2-4-4. 클러스터 시작 시의 메타데이터 구축

- 파일 시스템 이미지 DataNode : NameNode 시작 직후 메모리에 fsimage를 로드하고, edits를 적용해서 HDFS의 파일 시스템 이미지 최신화
- 블록 대응 정보 : 클러스터 시작 후, NameNode에게 DataNOde가 가지고 있는 블록을 신고함으로써 구축

#### 2-4-5. 파일과 디렉터리 권한

- POSIX 방식의 권한 모델 적용
- 파일에 관해서는 실행 권한이 의미를 가지지 못함
- setuid, setgid 비트 개념 X , sticky  비트는 O



## 3. MapReduce 프레임워크

### 3-1. MapReduce 처리

#### 3-1-1. 프레임워크의 처리 흐름

- Map, Shuffle&Sort, Reduce 단계를 거쳐 입력된 Job을 분할해 가며 처리 진행
- MapReduce 잡은 복수의 태스크로 분할
- Map 태스크와 Reduce 태스크는 각각 병렬 처리
- Map 처리가 끝난 후 Reduce 처리
- MapReduce 잡의 최종 결과는 HDFS에 출력

#### 3-1-2. 단계별 동작

##### Map 처리

- Map 처리의 입력 데이터를 **'스플릿(InputSplit)'**
- JobClient가 스플릿 단위 지정
- 입력 데이터는 HDFS 파일
- 스플릿 크기 = 블록 크기
- 스플릿에서 Key-value를 해석하고 1레코드씩 읽어 Map으로 처리

[이미지5]

- Map 처리 후 중간 출력 데이터는 로컬 디스크 사용
- Map 출력은 키를 기준으로 정렬
- 입력 데이터인 Key-value를 받아 사용자가 정의한 Map 처리를 실행하는 Mapper가 다시 Key-value 쌍 출력
- Partitioner를 통해 Reduce 처리를 하는 Reducer에게 전달

##### Shuffle&Sort 처리

- Map 출력이 Reduce까지 전달되는 일련의 과정

[이미지6]

- Reduce 처리를 하는 노드는 Map 처리를 수행한 복수의 노드 중 어딘가에 포함
- Mapper와 Reducer 간의 통신은 HTTP
- Reducer에 Map으로부터의 모든 데이터가 도달하면, Reduce 태스크에서 처리가 가능하도록 입력을 하나로 모으는 처리
- 복수의 Map에서 정렬된 조각들이 전달되기 때문에 병합-정렬로 집약
- Reduce 태스크의 입력은 키별로 정렬된 상태

##### Reduce 처리

- Reduce 처리의 입력을 **'파티션'** . Map 처리의 출력 결과인 Key-value가 키별 파티션으로 분할
- 같은 키로 모아진 중간 데이터에 대해 사용자가 정의한 Reduce 처리 실행
- Reduce 처리 결과로, 새로운 Key-value 쌍 생성하고 출력



### 3-2. MapReduce 아키텍처

#### 3-2-1. 노드 구성

- MapReduce 프레임워크에서 마스터 노드를 **'JobTracker'**, 슬레이브 노드를 **'TaskTracker'**
- HDFS의 슬레이브 노드인 DataNode는 MapReduce의 TaskTracker와 물리적으로 같은 장비에 설치
- MapReduce에 Job을 투입하는 클라이언트를 **'JobClient'**
- JobTracker는 하나의 hadoop 클러스터로 하나가 가동 / Hadoop 클러스터 상에서 동작하는 모든 MapReduce 잡을 관리

#### 3-2-2. JobTracker 역할

MapReduce 프레임워크가 제공하는 분산 처리를 제어하기 위한 프로세스로, 마스터로 동작하는 자바 프로세스

##### 잡 관리

- Map 태스크 할당 제어
- Map 처리 결과 파악
- 잡 진행 통지

##### 리소스 관리

- 처리 할당 : Map 처리나 Reduce 처리를 TaskTracker에 할당
- 처리의 주기적 실행
- 처리 재할당
- 블랙리스트화 : 처리 실패 빈도가 높은 TaskTracker에 처리 할당 X
- TaskTracker 동작 여부 확인
- TaskTracker 추가/제외

##### 잡 실행 이력 관리

- 잡 이력 관리

#### 3-2-3. TaskTracker 역할

- Child 프로세스 생성과 처리 실행
- Child 프로세스 상태 확인
- 처리 중지 통지
- Hearbeat 통신 : 정기적으로 JobTracker에 Heartbeat 전송
- Map 처리 수와 Reduce 처리 수 파악

#### 3-2-4. JobClient 역할

- 입력 데이터의 분할 방침 결정
- 잡 의뢰 : JobTracker에게 MapReduce 잡 실행 의뢰
- 애플리케이션 배포 : MapReduce 잡을 실행하기 위한 애플리케이션을 HDFS에 저장
- 진행 상태 수신
- 잡 관리 : 사용자 단위로 MapReduce 잡 관리



### 3-3. MapReduce와 HDFS 관계

#### 3-3-1. 스플릿

- MapReduce는 HDFS에서 데이터를 읽어 들이고, 처리 결과도 저장
- Map 태스크의 입력 데이터가 스플릿
- 스플릿은 고정 데이터, 처리 대상 입력 데이터를 분할한 조각들
- 하나의 Map 태스크는 하나의 스플릿에서 레코드를 읽어 처리

#### 3-3-2. 데이터 지역성(Data Locality)

데이터 배치 장소를 고려하여, 처리 프로그램을 데이터가 있는 곳으로 옮기는 것. MapReduce 처리를 할 때, 처리할 데이터가 존재하는 곳에서 처리될 수 있도록 NameNode와 통신하며 JobTracker가 태스크를 할당

- JobClient 동작 : 
- JobTracker가 태스크를 실행

#### 3-3-3. Job ID와 Task ID

#### 3-3-4. 태스크 할당



